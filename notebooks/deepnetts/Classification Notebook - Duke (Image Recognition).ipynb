{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe3732f",
   "metadata": {},
   "source": [
    "# Classification Notebook `Duke (Image Recognition)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799e059",
   "metadata": {},
   "source": [
    "## Add JupyterHelper and Download Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeefdb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%jars ../libs/JupyterHelper-1.0-SNAPSHOT-jar-with-dependencies.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87385185",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "\n",
    "<properties>\n",
    "    <deepnetts.version>1.12</deepnetts.version>\n",
    "    <visrec.version>1.0.1</visrec.version>\n",
    "</properties>\n",
    "\n",
    "<dependency>\n",
    "  <groupId>javax.visrec</groupId>\n",
    "  <artifactId>visrec-api</artifactId>\n",
    "  <version>1.0.1</version>\n",
    "</dependency>\n",
    "<dependency>\n",
    "  <groupId>javax.visrec</groupId>\n",
    "  <artifactId>visrec-ri</artifactId>\n",
    "  <version>1.0.1</version>\n",
    "  <type>jar</type>\n",
    "  <exclusions>\n",
    "      <exclusion>\n",
    "          <groupId>com.deepnetts</groupId>\n",
    "          <artifactId>deepnetts-core</artifactId>\n",
    "      </exclusion>\n",
    "  </exclusions>\n",
    "</dependency>\n",
    "<dependency>\n",
    "    <groupId>com.deepnetts</groupId>\n",
    "    <artifactId>deepnetts-core</artifactId>\n",
    "    <version>${deepnetts.version}</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25089fc9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df4c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.file.*;\n",
    "\n",
    "import java.io.ObjectInputStream;\n",
    "\n",
    "import deepnetts.core.DeepNetts;\n",
    "import deepnetts.data.ImageSet;\n",
    "import deepnetts.eval.ClassifierEvaluator;\n",
    "import deepnetts.eval.ConfusionMatrix;\n",
    "import deepnetts.net.ConvolutionalNetwork;\n",
    "import deepnetts.net.NeuralNetwork;\n",
    "import deepnetts.net.layers.activation.ActivationType;\n",
    "import deepnetts.net.loss.LossType;\n",
    "import deepnetts.net.train.BackpropagationTrainer;\n",
    "import deepnetts.util.FileIO;\n",
    "import javax.visrec.ml.eval.EvaluationMetrics;\n",
    "\n",
    "import ch.bytecrowd.JupyterHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf3417",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d9b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "var IMAGES_BASEURL   = \"https://raw.githubusercontent.com/deepnetts/deepnetts-communityedition/community-visrec/deepnetts-examples/datasets/DukeSet\";\n",
    "var IMAGE_NAMES_URL  = IMAGES_BASEURL + \"/train.txt\";\n",
    "var LABELS_NAMES_URL = IMAGES_BASEURL + \"/labels.txt\";\n",
    "\n",
    "var IMAGES_NAME_FILE = \"/tmp/train.txt\";\n",
    "var LABELS_FILE = \"/tmp/labels.txt\";\n",
    "\n",
    "var DUKE_IMAGES_DIR = \"/tmp/duke\";\n",
    "var NEGATIVE_IMAGES_DIR = \"/tmp/negative\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e54253",
   "metadata": {},
   "outputs": [],
   "source": [
    "JupyterHelper.downloadFile(IMAGE_NAMES_URL, IMAGES_NAME_FILE);\n",
    "JupyterHelper.downloadFile(LABELS_NAMES_URL, LABELS_FILE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c458f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Files saved to: /tmp/duke\n"
     ]
    }
   ],
   "source": [
    "Files.createDirectories(Paths.get(DUKE_IMAGES_DIR));\n",
    "Files.readAllLines(Paths.get(IMAGES_NAME_FILE)).stream()\n",
    "    .filter(line -> line.contains(\"duke\"))\n",
    "    .map(line -> line.replaceAll(\"duke/| duke\", \"\"))\n",
    "    .forEach(fileName -> {\n",
    "        JupyterHelper.downloadFile(IMAGES_BASEURL + \"/duke/\" + fileName, DUKE_IMAGES_DIR + \"/\" + fileName);\n",
    "    });\n",
    "\n",
    "System.out.println(\"[+] Files saved to: \" + DUKE_IMAGES_DIR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "542de315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Files saved to: /tmp/negative\n"
     ]
    }
   ],
   "source": [
    "Files.createDirectories(Paths.get(NEGATIVE_IMAGES_DIR));\n",
    "Files.readAllLines(Paths.get(IMAGES_NAME_FILE)).stream()\n",
    "    .filter(line -> line.contains(\"negative\"))\n",
    "    .map(line -> line.replaceAll(\"negative/| negative\", \"\"))\n",
    "    .forEach(fileName -> {\n",
    "        JupyterHelper.downloadFile(IMAGES_BASEURL + \"/negative/\" + fileName, NEGATIVE_IMAGES_DIR + \"/\" + fileName);\n",
    "    });\n",
    "    \n",
    "System.out.println(\"[+] Files saved to: \" + NEGATIVE_IMAGES_DIR);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce95d6d",
   "metadata": {},
   "source": [
    "## Prepare DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7005aa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 labels\n",
      "Loaded 73 images\n"
     ]
    }
   ],
   "source": [
    "int imageWidth = 64;\n",
    "int imageHeight = 64;\n",
    "\n",
    "String trainingFile = IMAGES_NAME_FILE;\n",
    "String labelsFile = LABELS_FILE;\n",
    "\n",
    "ImageSet imageSet = new ImageSet(imageWidth, imageHeight);\n",
    "imageSet.loadLabels(new File(labelsFile));\n",
    "imageSet.loadImages(new File(trainingFile));\n",
    "imageSet.zeroMean();\n",
    "imageSet.setInvertImages(true);\n",
    "imageSet.shuffle();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbced058",
   "metadata": {},
   "source": [
    "## Splitting Dataset (Train/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4701ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Splitting datasets\n",
      "Splitting data set: [0.7, 0.30000000000000004]\n",
      "[+] Training data size = 51 rows\n",
      "[+] Testing data size  = 21 rows\n"
     ]
    }
   ],
   "source": [
    "System.out.println(\"[+] Splitting datasets\");\n",
    "var test_train_ratio = 0.7;\n",
    "var trainTestSet = imageSet.split(test_train_ratio, 1 - test_train_ratio);\n",
    "System.out.println(String.format(\"[+] Training data size = %d rows\", trainTestSet[0].size()));\n",
    "System.out.println(String.format(\"[+] Testing data size  = %d rows\", trainTestSet[1].size()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ae0f2",
   "metadata": {},
   "source": [
    "## Create a Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a83f75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Creating the Neural Network\n",
      "Input Layer { width:64, height:64, depth:3 }\n",
      "Convolutional Layer { filter width:3, filter height: 3, channels: 3, stride: 1, activation: TANH}\n",
      "Max Pooling Layer { filter width:2, filter height: 2, stride:2}\n",
      "Fully Connected Layer { width:32 activation:TANH}\n",
      "Output Layer { width:1, activation:SIGMOID}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "System.out.println(\"[+] Creating the Neural Network\");\n",
    "ConvolutionalNetwork convNet = ConvolutionalNetwork.builder()\n",
    "    .addInputLayer(imageWidth, imageHeight, 3)\n",
    "    .addConvolutionalLayer(3, 3, 3, ActivationType.TANH)\n",
    "    .addMaxPoolingLayer(2, 2, 2)\n",
    "    .addFullyConnectedLayer(32, ActivationType.TANH)\n",
    "    .addOutputLayer(1, ActivationType.SIGMOID)\n",
    "    .lossFunction(LossType.CROSS_ENTROPY)\n",
    "    .build();\n",
    "\n",
    "convNet.setOutputLabels(imageSet.getTargetNames());\n",
    "\n",
    "System.out.println(convNet.toString());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8d051",
   "metadata": {},
   "source": [
    "## Train the Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6303545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "TRAINING NEURAL NETWORK\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch:1, Time:496ms, TrainError:0.49401402, TrainErrorChange:0.49401402, TrainAccuracy: 0.9019608\n",
      "Epoch:2, Time:352ms, TrainError:0.29076308, TrainErrorChange:-0.20325094, TrainAccuracy: 0.9411765\n",
      "Epoch:3, Time:355ms, TrainError:0.23669338, TrainErrorChange:-0.054069698, TrainAccuracy: 0.9411765\n",
      "Epoch:4, Time:352ms, TrainError:0.20153663, TrainErrorChange:-0.035156757, TrainAccuracy: 0.9411765\n",
      "Epoch:5, Time:339ms, TrainError:0.17167309, TrainErrorChange:-0.029863536, TrainAccuracy: 0.9607843\n",
      "Epoch:6, Time:350ms, TrainError:0.14497846, TrainErrorChange:-0.026694626, TrainAccuracy: 0.9607843\n",
      "Epoch:7, Time:348ms, TrainError:0.121782, TrainErrorChange:-0.023196466, TrainAccuracy: 0.9607843\n",
      "Epoch:8, Time:349ms, TrainError:0.102663875, TrainErrorChange:-0.019118123, TrainAccuracy: 0.9607843\n",
      "Epoch:9, Time:351ms, TrainError:0.0862938, TrainErrorChange:-0.016370073, TrainAccuracy: 0.9607843\n",
      "Epoch:10, Time:354ms, TrainError:0.07235454, TrainErrorChange:-0.013939261, TrainAccuracy: 1.0\n",
      "Epoch:11, Time:341ms, TrainError:0.06181382, TrainErrorChange:-0.01054072, TrainAccuracy: 1.0\n",
      "Epoch:12, Time:343ms, TrainError:0.054057486, TrainErrorChange:-0.007756334, TrainAccuracy: 1.0\n",
      "Epoch:13, Time:338ms, TrainError:0.047979575, TrainErrorChange:-0.0060779117, TrainAccuracy: 1.0\n",
      "\n",
      "TRAINING COMPLETED\n",
      "Total Training Time: 6193ms\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    " BackpropagationTrainer trainer = convNet.getTrainer();\n",
    "trainer.setMaxError(0.05f)\n",
    "    .setLearningRate(0.01f);\n",
    "\n",
    "trainer.train(trainTestSet[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84873272",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "292d32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Evaluating the model\n",
      "TrueNegative: 11.0\n",
      "Accuracy: 1.0 (How often is classifier correct in total)\n",
      "TotalClasses: 2.0\n",
      "FalsePositive: 0.0\n",
      "FalseNegative: 0.0\n",
      "Precision: 1.0 (How often is classifier correct when it gives positive prediction)\n",
      "F1Score: 1.0 (Average of precision and recall)\n",
      "TruePositive: 10.0\n",
      "TotalCorrect: 21.0\n",
      "TotalIncorrect: 0.0\n",
      "Recall: 1.0 (When it is actually positive class, how often does it give positive prediction)\n",
      "TotalItems: 21.0\n",
      "\n",
      "        negativepositive\n",
      "negative      11       0\n",
      "positive       0      10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "System.out.println(\"[+] Evaluating the model\");\n",
    "ClassifierEvaluator evaluator = new ClassifierEvaluator();\n",
    "EvaluationMetrics evalResults = evaluator.evaluate(convNet, trainTestSet[1]);\n",
    "System.out.println(evalResults);\n",
    "\n",
    "ConfusionMatrix cm = evaluator.getConfusionMatrix();\n",
    "System.out.println(cm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7a0c7",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "738dc0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Saving the model to: /tmp/DukeClassifier.dnet\n"
     ]
    }
   ],
   "source": [
    "var EXPORT_PATH = \"/tmp/DukeClassifier.dnet\";\n",
    "System.out.println(\"[+] Saving the model to: \" + EXPORT_PATH);\n",
    "FileIO.writeToFile(convNet, EXPORT_PATH);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1aac2",
   "metadata": {},
   "source": [
    "## Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e51e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Importing the model from: /tmp/DukeClassifier.dnet\n"
     ]
    }
   ],
   "source": [
    "System.out.println(\"[+] Importing the model from: \" + EXPORT_PATH);\n",
    "ConvolutionalNetwork neuralNet;\n",
    "try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(EXPORT_PATH))) {\n",
    "    neuralNet = ConvolutionalNetwork.class.cast(ois.readObject()) ;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "17.0.4+8-Debian-1deb11u1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
